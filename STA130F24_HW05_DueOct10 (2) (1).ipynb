{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae681ef",
   "metadata": {},
   "source": [
    "# STA130 Homework 05 \n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf135c01",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "    \n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Pre-lecture\" and \"Post-lecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "> It is *suggested but not mandatory* that you complete the \"Pre-lecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "> Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "    \n",
    "### Prompt Engineering? \n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da15ca",
   "metadata": {},
   "source": [
    "### Marking Rubric (which may award partial credit) \n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.3 points]: Evaluation of written communication for \"Question 2\"\n",
    "- [0.3 points]: Evaluation of written communication for \"Question 4\"\n",
    "- [0.3 points]: Evalution of submission for \"Question 8\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03b20c",
   "metadata": {},
   "source": [
    "## \"Pre-lecture\" HW [*completion prior to next LEC is suggested but not mandatory*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4eb39",
   "metadata": {},
   "source": [
    "### A. Watch this first pre-lecture video (\"Hypothesis testing. Null vs alternative\") addressing the question \"What is a hypothesis?\"<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _The video gives the example that the \"Hillary versus Trump\" U.S. presidential election campaign could not be turned into a hypothesis test assessing differences in performance between the two as U.S. presidents (because at the time of the election neither had been U.S. presidents). This is different than addressing \"Obama versus Bush\" within a hypothesis testing framework (because we have eight years worth of performance of both as U.S. presidents). A more contemporarily relevant comparison then would be the aborted election campaign efforts of \"Biden versus Trump\", which would have been a chimeric hybrid of the two comparisons mentioned above (because we have BOTH four years worth of DATA regarding the performance of both as U.S. presidents BUT we are also likely still [...or, were, prior to Biden dropping out of the presidential race...] interested in asking questions regarding their potential FUTURE performance of both as U.S. presidents for which we do not yet have any data). Anway, despite Biden dropping out of the election, we might still attempt to consider the record of the Biden presidency to be informative and predictive about the furture peformance of a potential Kamala Harris presidency._\n",
    "> \n",
    "> _This hopefully (a) makes the examples of the video more contemporarily relevant, and (b) gives another example to further emphasize and contrast the distinction that's being made in the video._\n",
    ">\n",
    "> _Also, while these are relatively knit-picky, two technical issues that the video somewhat inaccurately introduces are:_\n",
    ">\n",
    "> - _the video states that \"we accept the null hypothesis\"; but, actually it would be more correct to say, \"we fail to reject the null hypothesis\"_\n",
    "> - _the video specifies \"less than\" for the null hypothesis and \"less than or equal\" for the alternative hypothesis; but, actually, for mathematic reasons \"less than or equal\" version is the more technically correct choice for how the null hypothesis should be specified_\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c792af3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# First pre-lecture video: \n",
    "# \"Hypothesis testing. Null vs alternative\n",
    "# https://www.youtube.com/watch?v=ZzeXCKd5a18\n",
    "YouTubeVideo('ZzeXCKd5a18', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191182b",
   "metadata": {},
   "source": [
    "### B. Watch this second pre-lecture video (\"What is a p-value\") providing an intuitivie introduction to p-values <br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _This is intended to help you initially make more sense of the technical definition of a p-value, **the probability that a test statistic is as or more extreme than the observed test statistic if the null hypothesis was true**._\n",
    ">\n",
    "> _The thing is though, once you understand a p-value is, then you'll see how simple and elegant the above definition is... So, your objective in learning what a p-value is should be to be able to read and understand the definition of a p-value given above effortlessly... That way you can communicate with the language of statistical reasoning in 3.5 seconds rather than 3.5 minutes..._\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c80048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# Second pre-lecture video\n",
    "# \"What is a p-value\"\n",
    "# https://www.youtube.com/watch?v=9jW9G8MO4PQ\n",
    "YouTubeVideo('9jW9G8MO4PQ', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c8058",
   "metadata": {},
   "source": [
    "### 1. The \"first pre-lecture video\" (above) describes hypothesis testing as addressing \"an idea that can be tested\", and the end of the video then discusses what our actual intended purpose in setting up a null hypothesis is. What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically?  What would you describe is the key \"criteria\" defining what a good null hypothesis is? And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? Answer these questions with concise explanations in your own words.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _After watching and understanding both of the videos above, you should be well equipped to answer this and the following few questions. But, you can also interact with your favourite ChatBot to see if you understand the concepts correctly and to clarify any open questions you might have about anything that still seems unclear._\n",
    ">\n",
    "> HOWEVER, as we increasingly tread into the more conceptual statistical concepts of STA130, \"vanilla\" ChatBots become less and less reilable.\n",
    "> 1. First, \"vanilla\" ChatBots don't know the constraints and scope of the learning objectives of STA130, so in addition to their often verbose nature, they now present the possible risk of tangenting onto topics that do not concern (but may nonetheless potentially confuse and distract) us\n",
    "> 2. Second, ChatBots are based on textual information online, and while much of this information is accurate and well articulated, there is also a not insignificant presense of confusion and misunderstanding of statistical concepts and topics online. The downside of this is that since ChatBots don't \"reasons\" but instead just actually \"regurgitate\" the freqently occuring patterns between words found in text, it's increasingly possible that responses ChatBots will in fact amount to only meaningless gibberish nonensense.\n",
    ">\n",
    "> **Therefore, it is recommended that students begin considering and exploring increasingly relying on the STA130 Custom NotebookLM (NBLM) ChatBot** rather than \"vanilla\" ChatBots when it comes to the specific and technical and conceptual statistical topics of STA130.**\n",
    ">\n",
    "> _Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT) if you are using a ChatBot interaction to help learn and understand something!_\n",
    ">\n",
    "> In the case of the custom NBLM ChatBot, you can't get a transcript of your conversation, unfortunately (since converational history records outside of an active NBLM ChatBot session are made available to you in the future...); but, that's perfectly fine regarding the requirement of the homework which is only that a summary of any ChatBot interactions is provided with the submission. \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041b97d",
   "metadata": {},
   "source": [
    "### **Key Points about Null Hypothesis vs. Alternative Hypothesis**\n",
    "\n",
    "1. **Definition:**\n",
    "   - **Null Hypothesis (\\(H_0\\))**: Assumes no effect, no difference, or no relationship (e.g., \"No difference in scores between two methods\").\n",
    "   - **Alternative Hypothesis (\\(H_a\\))**: Claims there is an effect, difference, or relationship (e.g., \"There is a difference in scores\").\n",
    "\n",
    "2. **Formulation:**\n",
    "   - \\(H_0\\): Includes equality (\\(=\\), \\(\\geq\\), \\(\\leq\\)).\n",
    "   - \\(H_a\\): Includes inequality (\\(\\neq\\), \\(>\\), \\(<\\)).\n",
    "\n",
    "3. **Purpose in Testing:**\n",
    "   - \\(H_0\\): Acts as the baseline assumption.\n",
    "   - \\(H_a\\): Accepted only if sufficient evidence rejects \\(H_0\\).\n",
    "\n",
    "4. **Key Role:**\n",
    "   - Statistical tests aim to either reject \\(H_0\\) or fail to reject it. \\(H_0\\) is not \"proven true\" but remains accepted without evidence against it.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Makes a Hypothesis Suitable for Testing?**\n",
    "\n",
    "1. **Specific and Clear:** Hypotheses must be precise (e.g., \"Average score of Group A is higher than Group B\").\n",
    "2. **Testable and Measurable:** Must involve quantifiable data.\n",
    "3. **Falsifiable:** Can be proven false with data (e.g., \"Students studying more score higher\").\n",
    "4. **Population-Specific:** Clearly states the population (e.g., \"Engineering students at U of T\").\n",
    "5. **Neutral:** Avoids bias; \\(H_0\\) reflects no effect or difference.\n",
    "\n",
    "---\n",
    "\n",
    "- For equations or formatting, you can summarize like this:\n",
    "   - \\(H_0\\): No effect (e.g., \\(\\mu_A = \\mu_B\\)).\n",
    "   - \\(H_a\\): Difference exists (e.g., \\(\\mu_A \\neq \\mu_B\\)).\n",
    "- If you can't copy-paste equations, describe them clearly in plain text (e.g., \"Null hypothesis assumes average scores are equal between groups\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4637b0",
   "metadata": {},
   "source": [
    "### 2. Towards the end of the \"first pre-lecture\" video (above) it is stated that, \"It is important to note that outcomes of tests refer to the population parameter, rather than the sample statistic! As such, the result that we get is for the population.\" In terms of the distinctions between the concepts of $x_i\\!$'s, $\\bar x$, $\\mu$, and $\\mu_0$, how would you describe what the sentence above means? Explain this concisely in your own words for a \"non-statsitical\" audience, defining the technical statistical terminology you use in your answer.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _A formal **null hypothesis** has the form $H_0: \\mu=\\mu_0$ which states that the average value $\\mu$ of the population is $\\mu_0$, while the **alternative hypothesis** would then be $H_A: H_0 \\text{ is false}$ which states the average value $\\mu$ of the population is not $\\mu_0$. This question asks for a clear explanation of the distinguishing characteristics of the between the concepts of observed sample values $x_i$ (for $i = 1, \\cdots, n$), the observed sample average $\\bar x$, the actual value of $\\mu$, and the value $\\mu_0$ hypothesized under the null hypothesis relative to hypothesis testing._   \n",
    "> \n",
    "> _This question extends \"Question 7\" from the Week 4 HW that you considered last week in a more formal manner in terms of hypothesis testing notation. It should be getting much easier to delineate the differences between parameters and populations, and samples and statistics; and, to understand how to interpret and apply these concepts in the context of new topics (such as hypothesis testing, as is done here)._ \n",
    "> \n",
    "> _As continually suggested and encouraged regarding the topics of parameters, populations, samples, and statistics, check with your notes or your favourite ChatBot to make sure you have a clear understanding of these terms. At this point in the course, you should be able to read and understand of the meaning of the termenologically dense sentence addressed in the prompt to this question!_ \n",
    ">\n",
    "> Don't forget to ask for summaries of your ChatBot session(s) if you are using a ChatBot interaction to help learn and understand something! You only need to include link(s) to chat log histories if you're using ChatGPT, e.g., if you're using the custom STA130 NBLM ChatBot you can't get chat history logs, but you can get summaries, so just paste these into your homework notebook and indicate the both you're using if it can't provide links to chat log histories.\n",
    "    \n",
    "    \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b797e20",
   "metadata": {},
   "source": [
    "1. **Population Parameters vs. Sample Statistics:**\n",
    "   - **Population Parameters** (\\(\\mu\\), \\(\\sigma\\)): Fixed values that describe the entire population, usually unknown.\n",
    "   - **Sample Statistics** (\\(\\bar{x}\\), \\(s\\)): Values calculated from a sample, used to estimate population parameters.\n",
    "\n",
    "2. **Key Terms in Statistical Testing:**\n",
    "   - **Observations (\\(x_i\\))**: Individual data points in the sample.\n",
    "   - **Sample Mean (\\(\\bar{x}\\))**: Average of the sample data.\n",
    "   - **Population Mean (\\(\\mu\\))**: True average of the population.\n",
    "   - **Hypothesized Mean (\\(\\mu_0\\))**: The value assumed under the null hypothesis.\n",
    "\n",
    "3. **Relationship:**\n",
    "   - Sample statistics (\\(\\bar{x}\\)) help estimate or test hypotheses about population parameters (\\(\\mu\\)).\n",
    "\n",
    "4. **Testing Process:**\n",
    "   - Null hypothesis (\\(H_0\\)): \\(\\mu = \\mu_0\\) (e.g., \"Population mean is 170 cm\").\n",
    "   - Compare \\(\\bar{x}\\) to \\(\\mu_0\\) using statistical methods to decide if the difference is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2acde6",
   "metadata": {},
   "source": [
    "### 3. The second \"Pre-lecture\" video (above) explains that we \"imagine a world where the null hypothesis is true\" when calculating a p-value? Explain why this is in your own words in a way that makes the most sense to you.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Hint: your answer will likely be most efficiently correct and clear if it discusses the relavence of the sampling distribution of the test statistic under the null hypothesis._\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c23248",
   "metadata": {},
   "source": [
    "1. **Why Calculate p-Values Assuming \\(H_0\\) is True?**\n",
    "   - The p-value represents the probability of observing data as extreme as (or more extreme than) the actual data, assuming \\(H_0\\) is true.\n",
    "   - This assumption provides a benchmark to determine whether the observed data is unusual or expected under \\(H_0\\).\n",
    "   - A small p-value indicates that the observed data is unlikely under \\(H_0\\), providing evidence against it. A large p-value means the data is consistent with \\(H_0\\), so we fail to reject it.\n",
    "\n",
    "2. **What Does \"Assuming \\(H_0\\) is True\" Mean?**\n",
    "   - It means taking \\(H_0\\) as the starting point. For example:\n",
    "     - If \\(H_0\\) states that a coin is fair, we calculate probabilities based on \\(p = 0.5\\).\n",
    "     - If \\(H_0\\) states that the average height is 170 cm, we calculate probabilities based on \\(\\mu = 170\\).\n",
    "   - This assumption allows us to define the expected sampling distribution under \\(H_0\\).\n",
    "\n",
    "3. **Key Implications:**\n",
    "   - A **small p-value** suggests \\(H_0\\) is unlikely, so we reject it.\n",
    "   - A **large p-value** indicates insufficient evidence to reject \\(H_0\\).\n",
    "   - Assuming \\(H_0\\) is true does not prove \\(H_0\\); it simply provides a neutral basis for testing.\n",
    "\n",
    "### **Example:**\n",
    "- Testing whether a coin is fair (\\(H_0: p = 0.5\\)):\n",
    "  - Observing 70 heads in 100 flips, calculate the p-value assuming \\(H_0\\) is true.\n",
    "  - If the p-value is very small (e.g., 0.001), reject \\(H_0\\), concluding the coin is likely biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362fa03",
   "metadata": {},
   "source": [
    "### 4. The second \"Pre-lecture\" video (above) suggests that a smaller p-value makes the null hypothesis look more ridiculous. Explain why this is in your own words in a way that makes the most sense to you, clarifying the meaning of any technical statistical terminology you use in your answer.<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Hint: your answer will likely be most efficiently correct and clear if it discusses how the observed test statistic relates to the sampling distribution of the test statistic under the null hypothesis._\n",
    "    \n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb0ae4",
   "metadata": {},
   "source": [
    "1. **Why Does a Smaller p-Value Make \\(H_0\\) Less Believable?**\n",
    "   - The p-value represents the probability of observing data as extreme as (or more extreme than) the actual data, assuming \\(H_0\\) is true.\n",
    "   - A smaller p-value indicates that the observed result is very unlikely under \\(H_0\\), making \\(H_0\\) less credible.\n",
    "\n",
    "2. **What Does This Mean in Statistical Testing?**\n",
    "   - If \\(H_0\\) is true, the data should align with its predictions. A small p-value suggests the data deviates significantly from these predictions, providing evidence against \\(H_0\\).\n",
    "   - When \\(p \\leq 0.05\\) (a typical threshold), we reject \\(H_0\\) because the observed data is too unlikely to occur by chance.\n",
    "\n",
    "3. **Key Takeaways:**\n",
    "   - **Small p-value (\\(p \\leq 0.05\\)):** Strong evidence against \\(H_0\\); reject \\(H_0\\).\n",
    "   - **Large p-value (\\(p > 0.05\\)):** Data is consistent with \\(H_0\\); fail to reject \\(H_0\\).\n",
    "\n",
    "### **Example:**\n",
    "- Testing if a coin is fair (\\(H_0: p = 0.5\\)):\n",
    "  - Observing 80 heads in 100 flips yields a very small p-value (\\(p \\approx 0.0001\\)).\n",
    "  - Since \\(p < 0.05\\), \\(H_0\\) is unlikely, so we reject it and conclude the coin is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e9c25",
   "metadata": {},
   "source": [
    "### 5. Güntürkün (2003) recorded how kissing couples tilt their heads. 80 out of 124 couples, or 64.5% tilted their heads to the right. Simulate a **p-value** using a \"50/50 coin-flipping\" model for the assumption of the **null hypothesis** $H_0$ that the population of humans don't have left or right head tilt tendencies when kissing, and use the table below to determine the level of evidence we have against $H_0$. <br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _The previous three \"Questions 2-4\" are highly relevant here. For this question, you need to first (along the lines of \"Question 2\") understand what the problem context describes to you in terms of something analogous to $x_i\\!$'s, $\\bar x$, $\\mu$, and $\\mu_0$. Then you need to (along the lines of \"Question 3\") figure out how to \"imagine a world where the null hypothesis is true\" so that you can go about computing a (**simulation** based) p-value calcuation for the null hypothesis under consideration relative to the available data. And finally, you need to make a determination about your potential decision to reject the null hypothesis on the strength of the data at hand on the basis of the \"strength of evidence\" table given below (which indeed supports the necessary interpretation required to provide an explanation answering \"Question 4\")._\n",
    ">    \n",
    "> _Regarding Güntürkün (2003) itself, click [here](https://www.nature.com/articles/news030210-7) if you want to know more!_    \n",
    "    \n",
    "</details> \n",
    "\n",
    "\n",
    "|p-value|Evidence|\n",
    "|-|-|\n",
    "|$$p > 0.1$$|No evidence against the null hypothesis|\n",
    "|$$0.1 \\ge p > 0.05$$|Weak evidence against the null hypothesis|\n",
    "|$$0.05 \\ge p > 0.01$$|Moderate evidence against the null hypothesis|\n",
    "|$$0.01 \\ge p > 0.001$$|Strong evidence against the null hypothesis|\n",
    "|$$0.001 \\ge p$$|Very strong evidence against the null hypothesis|\n",
    "\n",
    "![Rodin's sculpture, \"The Kiss\"\n",
    "](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/Rodin_-_Le_Baiser_06.jpg/409px-Rodin_-_Le_Baiser_06.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd54e6",
   "metadata": {},
   "source": [
    "1. **Null Hypothesis (\\(H_0\\))**: Couples tilt their heads to the right 50% of the time (\\(p = 0.5\\)).\n",
    "\n",
    "2. **Simulation Process:**\n",
    "   - Assume \\(H_0\\) is true (\\(p = 0.5\\)).\n",
    "   - Simulate many random samples of 124 couples, each with a 50% chance of tilting right.\n",
    "   - Calculate the proportion of samples with proportions as extreme as the observed value (\\(0.645\\)).\n",
    "\n",
    "3. **Result:**\n",
    "   - The simulated p-value is **0.00173**.\n",
    "\n",
    "4. **Interpretation:**\n",
    "   - A p-value of 0.00173 indicates very strong evidence against \\(H_0\\).\n",
    "   - Since \\(p < 0.05\\), reject \\(H_0\\). The observed data suggests that couples are biased towards tilting their heads to the right. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4131b13",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Continue now...?</u></summary>\n",
    "\n",
    "### Pre-lecture VS Post-lecture HW\n",
    "\n",
    "Feel free to work on the \\\"Postlecture\\\" HW below if you're making good progress and want to continue: the next questions will continue addressing and building on the topics from the videos, so, it's just a choice whether or not you want to work a head a little bit...\n",
    "    \n",
    "*The benefits of continue would are that (a) it might be fun to try to tackle the challenge of working through some problems without additional preparation or guidance; and (b) this is a very valable skill to be comfortable with; and (c) it will let you build experience interacting with ChatBots (and beginning to understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as course provided resources or a plain old websearch for the right resourse) would be more effective*\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ddd69",
   "metadata": {},
   "source": [
    "## \"Post-lecture\" HW [*submission along with \"Pre-lecture\" HW is due prior to next TUT*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c4f25",
   "metadata": {},
   "source": [
    "### 6. Can a smaller p-value definitively prove that the null hypothesis is false? Is it possible to definitively prove that Fido (from the \"second pre-lecture video\") is innocent using a p-value? Is it possible to difinitively prove that Fido is guilty using a p-value? How low or high does a p-value have to be to definitely prove one or the other? Explain this concisely in your own words.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191966e9",
   "metadata": {},
   "source": [
    "1. **p-Values Cannot Prove Truth or Falsehood:**\n",
    "   - A p-value measures the likelihood of the observed data under \\(H_0\\), but it does not prove \\(H_0\\) is true or false.\n",
    "   - It reflects the compatibility of the data with \\(H_0\\), not absolute certainty.\n",
    "\n",
    "2. **Low p-Value (\\(p \\leq 0.05\\)):**\n",
    "   - Indicates the data is unlikely under \\(H_0\\).\n",
    "   - Suggests **strong evidence against \\(H_0\\)**.\n",
    "   - Leads to rejecting \\(H_0\\), but does not confirm \\(H_a\\).\n",
    "\n",
    "3. **High p-Value (\\(p > 0.05\\)):**\n",
    "   - Indicates the data is consistent with \\(H_0\\).\n",
    "   - Suggests **insufficient evidence to reject \\(H_0\\)**.\n",
    "   - Does not prove \\(H_0\\) is true; there may still be an undetected effect.\n",
    "\n",
    "4. **Key Takeaway:**\n",
    "   - A p-value is **not proof** but a measure of evidence. It must be interpreted with context, considering sample size, study design, and other factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87883773",
   "metadata": {},
   "source": [
    "### 7. In the second half of the \"first pre-lecture video\" the concept of a \"one sided\" (or \"one tailed\") test is introduced in contrast to a \"two sided\" (or \"two tailed\") test. Work with a ChatBot to adjust the code from \"Demo II of  the Week 5 TUT\" (which revisits the \"Vaccine Data Analysis Assignment\" from Week 04 HW \"Question 8\") in order to compute a p-value for a \"one sided\" (or \"one tailed\") hypothesis test rather than the \"two sided\" (or \"two tailed\") version it provides. Describe (perhaps with the help of your ChatBot) what changed in the code; how this changes the interpretation of the hypothesis test; and whether or not we should indeed expect the p-value to be smaller in the \"one tailed\" versus \"two tailed\" analysis. <br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _[Demo II of the The Week 5 TUT](https://github.com/pointOfive/stat130chat130/blob/main/TUT/STA130F24_TUT05_Oct04.ipynb) revisiting the \"[Vaccine Data Analysis Assignment](https://github.com/pointOfive/stat130chat130/blob/main/HW/STA130F24_HW04_DueOct03.ipynb)\" illustrates using simulation to estimate a two-sided (or \"two tailed\") p-value._\n",
    ">\n",
    "> _The notion of \"one sided\" or \"two sided\" tests is also referred to as \"one tailed\" or \"two tailed\" because (other than using \"$\\leq$\" and \"$>$\" [or \"$\\geq$\" and \"$<$\"] rather than \"$=$\" and \"$\\neq$\" when specifying $H_0$ and $H_A$) the actual place where this distinction has a practical impact is in the calculation of p-values, which is done in the \"tails\" of the sampling distribution of the statistic of interest under the assumption that the null hypothesis is true._\n",
    ">\n",
    "> Don't forget to ask for summaries of your ChatBot session(s) if you are using a ChatBot interaction to help learn and understand something! You only need to include link(s) to chat log histories if you're using ChatGPT, e.g., if you're using the custom STA130 NBLM ChatBot you can't get chat history logs, but you can get summaries, so just paste these into your homework notebook and indicate the both you're using if it can't provide links to chat log histories.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d97cfb",
   "metadata": {},
   "source": [
    "Adjusting the Code\n",
    "In a one-tailed test, you calculate the p-value based only on the probability of observing results in the specified direction:\n",
    "\n",
    "For Testing if Proportion is Greater (\n",
    "𝐻\n",
    "𝑎\n",
    ":\n",
    "𝑝\n",
    ">\n",
    "0.5\n",
    "H \n",
    "a\n",
    "​\n",
    " :p>0.5):\n",
    "\n",
    "The p-value is the proportion of simulations where the sample proportion is greater than or equal to the observed proportion.\n",
    "For Testing if Proportion is Less (\n",
    "𝐻\n",
    "𝑎\n",
    ":\n",
    "𝑝\n",
    "<\n",
    "0.5\n",
    "H \n",
    "a\n",
    "​\n",
    " :p<0.5):\n",
    "\n",
    "The p-value is the proportion of simulations where the sample proportion is less than or equal to the observed proportion.\n",
    "Here's how the code changes for the one-tailed test:\n",
    "\n",
    "Modified Code for a One-Tailed Test\n",
    "Let’s assume we are testing \n",
    "𝐻\n",
    "𝑎\n",
    ":\n",
    "𝑝\n",
    ">\n",
    "0.5\n",
    "H \n",
    "a\n",
    "​\n",
    " :p>0.5 (the proportion of couples tilting right is greater than 50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64bcaa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6451612903225806, 0.00075)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n_trials = 124  # Number of couples\n",
    "p_null = 0.5    # Null hypothesis proportion\n",
    "observed_count = 80  # Observed count of right tilts\n",
    "n_simulations = 100_000  # Number of simulations\n",
    "\n",
    "# Simulate the null distribution\n",
    "simulated_counts = np.random.binomial(n_trials, p_null, size=n_simulations)\n",
    "\n",
    "# Calculate proportions\n",
    "observed_proportion = observed_count / n_trials\n",
    "simulated_proportions = simulated_counts / n_trials\n",
    "\n",
    "# One-tailed test: Greater than observed proportion\n",
    "p_value_one_tailed = np.mean(simulated_proportions >= observed_proportion)\n",
    "\n",
    "observed_proportion, p_value_one_tailed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8609417c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6451612903225806, 0.99968)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-tailed test: Less than observed proportion\n",
    "p_value_one_tailed = np.mean(simulated_proportions <= observed_proportion)\n",
    "\n",
    "observed_proportion, p_value_one_tailed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08275da5",
   "metadata": {},
   "source": [
    "Why is the p-Value Smaller in a One-Tailed Test?\n",
    "Focus on One Direction:\n",
    "\n",
    "A one-tailed test evaluates only one direction of extreme results (e.g., either greater than or less than the observed value).\n",
    "In a two-tailed test, the p-value considers extremities in both directions (e.g., values much greater and much smaller than expected).\n",
    "Reduced Area in Tail:\n",
    "\n",
    "By concentrating on just one tail, the probability is calculated for only one side of the distribution, effectively halving the area considered in the two-tailed test.\n",
    "Stronger Evidence Needed:\n",
    "\n",
    "A one-tailed test assumes you have a specific hypothesis about the direction of the effect. Because of this, it’s more sensitive to deviations in that direction and leads to a smaller p-value if the observed effect aligns with the hypothesized direction.\n",
    "Example of the Difference\n",
    "Two-tailed test: Testing \n",
    "𝐻\n",
    "𝑎\n",
    ":\n",
    "𝑝\n",
    "≠\n",
    "0.5\n",
    "H \n",
    "a\n",
    "​\n",
    " :p\n",
    "\n",
    "=0.5.\n",
    "\n",
    "Observing \n",
    "𝑝\n",
    "=\n",
    "0.645\n",
    "p=0.645 results in a p-value that combines the probabilities in both tails of the distribution.\n",
    "One-tailed test: Testing \n",
    "𝐻\n",
    "𝑎\n",
    ":\n",
    "𝑝\n",
    ">\n",
    "0.5\n",
    "H \n",
    "a\n",
    "​\n",
    " :p>0.5.\n",
    "\n",
    "Observing \n",
    "𝑝\n",
    "=\n",
    "0.645\n",
    "p=0.645 results in a p-value that considers only the right tail (greater than 0.645)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c953507",
   "metadata": {},
   "source": [
    "### 8. Complete the following assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f9956",
   "metadata": {},
   "source": [
    "### Fisher's Tea Experiment Data Analysis Assignment\n",
    "\n",
    "**Overview**\n",
    "\n",
    "A most beloved piece of [statistical lore](https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2012.00620.x) about the (most famous) statistician Ronald Fisher involves cups of tea with milk. Fisher and his friend and colleague, Dr. Muriel Bristol, worked at Cambridge in the 1920s and regularly had tea together. During one of their afternoon tea times, Bristol refused a cup of tea from Fisher because he put milk in first BEFORE pouring in the tea. Bristol said she could taste the difference, and much preferred the taste of tea when the milk was poured in afterward the tea. Fisher didn't think that there could be a difference and proposed a hypothesis test to examine the situation.\n",
    "\n",
    "Fisher made 8 cups of tea, 4 with milk added in first and 4 with tea added in first, and gave them to Dr. Bristol without her seeing how they were made and she would say if she thought the tea or the milk was poured first. As it turned out, Bristol correctly identified if the tea or milk was poured first for all 8 of the cups. Fisher, being a skeptical statistician wanted to test if this could be happening by chance with Bristol just randomly guessing (or whether there was evidence against an assumption of Bristol just randomly guessing), and subsequently designed a statistical hypothesis test to do so.\n",
    "\n",
    "Suppose you run an experiment like this with students in STA130. You get a random sample of 80 STA130 students to each taste one cup of tea and tell you whether they think the milk or tea was poured first. **Suppose 49 students are able to correctly state which was poured first.** Provide a statistical analysis of this experiment as guided through the following set of questions.\n",
    "\n",
    "**Data**\n",
    "\n",
    "49 out of a sample of 80 students are able to correctly state which was poured first.\n",
    "\n",
    "**Deliverables**\n",
    "\n",
    "While you can choose how to approach the project, we are interested in evaluating your report relative to the following deliverables: \n",
    "- Clarity of your documentation, code, and written report \n",
    "- Description of the population (and sample) and parameter of interest (and corresponding observed test statistic) \n",
    "- Formal null hypotheses $H_0$ \n",
    "    - Provide a formal version $H_0$ based on the population parameter \n",
    "    - Provide an informal interpretive statement explaining $H_0$ in more casual everyday common language\n",
    "    - Alternative hypothesis $H_A$ in terms of $H_0$\n",
    "- Quantitative analysis addressing the validity of $H_0$\n",
    "    - Explanation of the method clearly articulating the purpose of the usage of statistic(s) to address $H_0$ the population parameter of interest \n",
    "\n",
    "\n",
    "**Comments**\n",
    "\n",
    "- Regarding the population (and the sample), there is a clear difference between the experiment with STA130 students considered here and the original motivating experimental context of Fisher and Bristol.\n",
    "    - the sample size is different.\n",
    "    - but so too is the nature of the population. the parameter in question might be considered more personalized in the original experiment; whereas, the parameter in the context of STA130 students might be a more abstract concept\n",
    "- The analysis here could be approached from the perspective of formal hypothesis testing.\n",
    "    - which would likely involve the simulation of a sampling distribution under $H_0$ in order to estimate p-value with respect to the null hypothesis based on the observed test statistic (how?), concluding with the assement of $H_0$ based on an interpretation of the meaning of the p-value relative to $H_0$\n",
    "    - but a confidence interval approach to considering the hypothesis could also be considered.\n",
    "\n",
    "> Consider organizing your report within the following outline template.\n",
    "> - Problem Introduction \n",
    ">     - Relationship between this experiment and the original with Fisher and Bristol\n",
    ">     - Statements of the Null Hypothesis and Alternative hypothesis\n",
    "> - Quantitative Analysis\n",
    ">     - Methodology Code and Explanations\n",
    ">     - *(if needed/optional)* Supporting Visualizations \n",
    "> - Findings and Discussion\n",
    ">     - Conclusion regarding the Null Hypothesis\n",
    "\n",
    "#### Further Instructions:\n",
    "- When using random functions, you should make your analysis reproducible by using the `np.random.seed()` function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ecc69",
   "metadata": {},
   "source": [
    "1. Define the Null and Alternative Hypotheses\n",
    "Null Hypothesis (\n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " ):\n",
    "\n",
    "The participants have no ability to correctly identify the poured order, and their guesses are purely random.\n",
    "Mathematically, the probability of correctly identifying the poured order is \n",
    "𝑝\n",
    "=\n",
    "0.5\n",
    "p=0.5.\n",
    "Alternative Hypothesis (\n",
    "𝐻\n",
    "𝑎\n",
    "H \n",
    "a\n",
    "​\n",
    " ):\n",
    "\n",
    "The participants have some ability to identify the poured order, making the probability of success different from random guessing.\n",
    "Mathematically, \n",
    "𝑝\n",
    "≠\n",
    "0.5\n",
    "p\n",
    "\n",
    "=0.5 (two-tailed test).\n",
    "2. Set Up the Statistical Test\n",
    "The experiment involves binary outcomes (correct or incorrect identification), so we can model it as a binomial test:\n",
    "\n",
    "Parameters:\n",
    "Number of trials (\n",
    "𝑛\n",
    "n) = 80\n",
    "Observed successes (\n",
    "𝑘\n",
    "k) = 49\n",
    "Null hypothesis success probability (\n",
    "𝑝\n",
    "0\n",
    "p \n",
    "0\n",
    "​\n",
    " ) = 0.5\n",
    "3. Perform the Statistical Test\n",
    "Calculate the Test Statistic: Use the binomial distribution to calculate the probability of observing 49 or more correct identifications (or 31 or fewer, in a two-tailed test).\n",
    "\n",
    "Simulate or Calculate p-value: The p-value is the probability of observing a result as extreme as or more extreme than 49 correct identifications, assuming \n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    "  is true.\n",
    "\n",
    "4. Interpret the Results\n",
    "Compare the p-value to a significance level (\n",
    "𝛼\n",
    "α, often 0.05).\n",
    "If \n",
    "𝑝\n",
    "≤\n",
    "𝛼\n",
    "p≤α: Reject \n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " , suggesting evidence of an ability to identify the poured order.\n",
    "If \n",
    "𝑝\n",
    ">\n",
    "𝛼\n",
    "p>α: Fail to reject \n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " , suggesting insufficient evidence to claim the participants have this ability.\n",
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446345c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6125, 0.056664426345121144)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "# Parameters\n",
    "n = 80  # Total participants\n",
    "k = 49  # Participants who guessed correctly\n",
    "p_null = 0.5  # Null hypothesis success probability\n",
    "\n",
    "# Perform a two-tailed binomial test\n",
    "result = binomtest(k, n, p_null, alternative='two-sided')\n",
    "\n",
    "# Extract observed proportion and p-value\n",
    "observed_proportion = k / n\n",
    "p_value = result.pvalue\n",
    "\n",
    "observed_proportion, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d1dd2b",
   "metadata": {},
   "source": [
    "5. Results Interpretation\n",
    "Observed Proportion:\n",
    "\n",
    "𝑝\n",
    "^\n",
    "=\n",
    "49\n",
    "80\n",
    "=\n",
    "0.6125\n",
    "p\n",
    "^\n",
    "​\n",
    " = \n",
    "80\n",
    "49\n",
    "​\n",
    " =0.6125\n",
    "This is the observed proportion of correct identifications.\n",
    "p-Value:\n",
    "\n",
    "The p-value tells us how likely it is to observe 49 or more correct identifications (or 31 or fewer) under the null hypothesis.\n",
    "Conclusion:\n",
    "\n",
    "If the p-value is small (e.g., \n",
    "𝑝\n",
    "≤\n",
    "0.05\n",
    "p≤0.05), it suggests the observed results are unlikely to occur under \n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " , indicating participants may have the ability to identify the poured order.\n",
    "If the p-value is large (\n",
    "𝑝\n",
    ">\n",
    "0.05\n",
    "p>0.05), the results are consistent with random guessing, and we fail to reject \n",
    "𝐻\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae7e80",
   "metadata": {},
   "source": [
    "### 9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    " \n",
    ">  _Here is the link of [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) in case it gets lost among all the information you need to keep track of_  : )\n",
    ">    \n",
    "> _Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)_\n",
    "    \n",
    "</details>\n",
    "\n",
    "_**Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)!**_ **But if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a8360",
   "metadata": {},
   "source": [
    "Yes, I have reviewed the course wiki-textbook and interacted with a ChatBot to clarify concepts I initially found challenging. I also utilized additional resources like tutorial materials and lecture slides to reinforce my understanding.\n",
    "\n",
    "If needed, I would consult the Piazza discussion board or attend TA office hours for further clarification to ensure that I fully grasp all aspects of the material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d270f",
   "metadata": {},
   "source": [
    "This link contains the chat history between me and ChatGPT while completing this assignment.https://chatgpt.com/share/675248ea-dfa4-8007-8b21-4c3423b74d49"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aab1be",
   "metadata": {},
   "source": [
    "## Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course \n",
    "\n",
    "<br>\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "    \n",
    "### Ethical Professionalism Considerations\n",
    "    \n",
    "Using p-values and hypothesis testing appropriately is an important ethical and professional responsibility of anyone doing data analysis. Actually, there is quite the quiet Contra-Versy (or is it Con-TROV-ersy?) around p-values. First, on a general level, it seems quite clear that p-values and hypothesis testing methodologies MUST play some ongoing contributing role in the so-called \"replication crisis\" rampantly afflicting mordern science; namely, \"significant findings\" made in scientific studies are not able to be reproduced by future studies at an alarming rate; and, this whole paradigm of \"significant findings\" is based on p-values and hypothesis testing... so, something's going on with this methodology in some way...\n",
    "    \n",
    "More specifically however, p-values are themselves quite problematic. To see this, just briefly consider the following article titles...\n",
    "\n",
    "- [Why are p-values controversial?](https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1277161) \n",
    "- [What a nerdy debate about p-values shows about science and how to fix it](https://www.vox.com/science-and-health/2017/7/31/16021654/p-values-statistical-significance-redefine-0005)\n",
    "- [The reign of the p-value is over: what alternative analyses could we employ to fill the power vacuum?](https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174)\n",
    "- [Scientists rise up against statistical significance](https://www.nature.com/articles/d41586-019-00857-9)\n",
    "- [Statistics experts urge scientists to rethink the p-value](https://www.spectrumnews.org/news/statistics-experts-urge-scientists-rethink-p-value)\n",
    "\n",
    "While the issues here are relatively advanced and subtle (as introduced [here](https://www2.stat.duke.edu/~berger/p-values.html), presented [here](https://www.jarad.me/courses/stat587Eng/slides/Inference/I06-Pvalues/why_pvalues_dont_mean_what_you_think_they_mean.pdf), and demonstrated using simulation [here](https://jaradniemi.shinyapps.io/pvalue/)), the problem essentially comes down to the fact that most scientists (or just people) don't know how to really interpret the numeric value of a p-value. There are therefore two current proposed solutions to address this challenge.\n",
    "    \n",
    "1. Just interpreting p-values using the follwing table (which really isn't that hard, so it's surprising that this solution isn't more broadly adopted...)\n",
    "    \n",
    "|p-value|Evidence|\n",
    "|-|-|\n",
    "|$$p > 0.1$$|No evidence against the null hypothesis|\n",
    "|$$0.1 \\ge p > 0.05$$|Weak evidence against the null hypothesis|\n",
    "|$$0.05 \\ge p > 0.01$$|Moderate evidence against the null hypothesis|\n",
    "|$$0.01 \\ge p > 0.001$$|Strong evidence against the null hypothesis|\n",
    "|$$0.001 \\ge p$$|Very strong evidence against the null hypothesis|\n",
    "    \n",
    "\n",
    "2. Only do **hypothesis testing** on the basis of confidence intervals, not **p-values** (which might be the best solution wherever doing so is a realistic, convenient  possibility...)\n",
    "\n",
    "With this quite broad introductory context in mind, what does your favorite ChatBot thinks about the following statements? \n",
    "    \n",
    "1. Hypothesis testing is not a \"mathematical proof\"<br><br>\n",
    "\n",
    "    1. We do not prove $H_0$ false, we instead give evidence against the $H_0$: \"We reject the null hypothesis with a p-value of XYZ, meaning we have ABC evidence against the null hypothesis\"\n",
    "    2. We do not prove $H_0$ is true, we instead do not have evidence to reject $H_0$: \"We fail to reject the null hypothesis with a p-value of XYZ\"<br><br>\n",
    "\n",
    "2. Implying that a \"non-significant result\" means there is \"no effect\" misleads an audience because this may in actual fact simply indicate that there was insufficient evidence to reject the null hypothesis. So this therefore overlooks the possibility of sample size limitations, or Type II errors (which means a test incorrectly concludes that there is no effect or difference when, in fact, there is one). \n",
    "    \n",
    "> Similarly, analagously, a \"significant result\" used to reject the null hypothsis could alternatively be a Type I error (which means a test actually incorrectly rejected a null hypothesis when it was actually true)... we're only providing a measure of evidence against the null hypothesis... but the evidence could still incorrectly suggest the wrong conclusion... it really depends on how strong the evidence is...\n",
    ">\n",
    "> - all of which is why just interpreting p-values using the table above is a good idea...\n",
    "\n",
    "3. The p-values used for hypothesis testing are contructed upone the assumptions of the null hypotheses they correspond to; but, null hypotheses are actually often presented in simple forms that routinely hide a lot of information that is implicitly used to construct the p-values. For example, distributional assumptions about the population, estimated \"plug-in\" values that can used to simplify the problem calculations, and the reliance upon \"random sampling\", etc...<br><br>\n",
    "           \n",
    "4. Drawing overly broad conclusions, or making recommendations based on findings that reject the null hypothesis in a specific context is fraught with the problematic risks of overgeneralization errors. Further exacerbating this issue, null hypotheses are typically so called \"point null hypotheses\" which is meant to emphasize that they are mathematically increadibly sharply specific; whereas, alternative hypotheses are usually very unspecific. An alternative hypothesis that \"the null hypothesis is false\" doesn't say much... we should wonder, \"how, specfically, is the null false?\"\n",
    "    \n",
    "As an example really giving a demonstrating this, consider rejecting a null hypothesis that there is no correlation between rain and pizza's delivered. Such a decision doesn't specify what the actual hypothetical correlation might be. In fact, it doesn't even indicate if there are more or less pizzas delivered when it rains... \n",
    "\n",
    "> which, actually, shows very clearly why statistical inference using hypothesis testing is inferior to statistical inference based on confidence intervals...\n",
    "> \n",
    "> - a confidence interval provides a range of plausible values of what the parameter in question might be; whereas, ...\n",
    "> - trying to more clearly address what the plausible values of the parameter in question might be on the basis of hypothesis testing would require conducting further experiements to continously reject increasingly detailed hypothesies to narrow down what the alternative hypothesis might actually include... which would indeed be an utterly vapid misuse of the intended purpose of hypothesis testing entrprise... \n",
    "    \n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "    \n",
    "### Current Course Project Capability Level\n",
    "    \n",
    "**Remember to abide by the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) at all times.**\n",
    "\n",
    "Information about the course project is available on the course github repo [here](https://github.com/pointOfive/stat130chat130/tree/main/CP), including a draft [course project specfication](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F23_course_project_specification.ipynb) (subject to change). \n",
    "- The Week 01 HW introduced [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb), and the [available variables](https://drive.google.com/file/d/1ISVymGn-WR1lcRs4psIym2N3or5onNBi/view). \n",
    "- Please do not download the [data](https://drive.google.com/file/d/1mbUQlMTrNYA7Ly5eImVRBn16Ehy9Lggo/view) accessible at the bottom of the [CSCS](https://casch.org/cscs) webpage (or the course github repo) multiple times.\n",
    "    \n",
    "> ### NEW DEVELOPMENT<br>New Abilities Achieved and New Levels Unlocked!!!    \n",
    "> **As noted, the Week 01 HW introduced the [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb) notebook.** _And there it instructed students to explore the notebook through the first 16 cells of the notebook._ The following cell in that notebook (there marked as \"run cell 17\") is preceded by an introductory section titled, \"**Now for some comparisons...**\", _**and all material from that point on provides an example to allow you to start applying what you're learning about Hypothesis Testing to the CSCS data**_ as now suggested next below.\n",
    "\n",
    "    \n",
    "At this point in the course there should be two kinds of hypothesis testing analyses you should be able to use to provide evidence against a null hypothesis (about some of the interesting columns from the Canadian Social Connection Survey data):\n",
    "    \n",
    "1. Any \"before and after\" data that can be made into differences can be used to test a null hypothesis of \"no effect\" of an intervention on the average change in the population (as illustrated through the example of the Week 5 TUT **Demo**)\n",
    "    \n",
    "2. Any binary data that could be approached analagously to the \"Stella's Wheel of Destiny\" example of the Week 5 TUT **Communication Activity** can be used to test a null hypothesis about the (population) chance of success `p` (using a `np.random.choice([0,1], p)` population to simulate the sampling distribution under the null)\n",
    "    \n",
    "    1. [For Advanced Students Only] And actually, hypothesis testing for other numerical data could be approached analagously to the method based on assuming a distibution for the population (such as `stats.norm(loc=mu0, scale=x.std)` in place of `np.random.choice([0,1], p)`... if you see what this means?)\n",
    "    2. Or it could be based on seeing if a hypothesized parameter value was contained within a bootstrapped confidence interval...\n",
    "    \n",
    "\n",
    "1. How do hypothesis testing analyses correspond to bootstrapped confidence intervals? \n",
    "    \n",
    "2. Create a **null hypothesis** about a population parameter than you can test using the Canadian Social Connection Survey data\n",
    "\n",
    "3. Carry out the hypothesis test using simulation, and interpret the result of the estimated p-value relative to the null hypothesis\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4f128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
